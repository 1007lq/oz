1.  More OS support:
     - Ubuntu 5.04 and 5.10
     - Debian Etch, Lenny, Squeeze
     - SUSE Linux 10.0, 10.1
     - openSUSE 10.2, 10.3 (autoyast)
     - OpenBSD (http://people.cs.uchicago.edu/~brendan/howtos/openbsd_install/)
     - NetBSD (anita)
     - FreeBSD
     - Dragonfly BSD
     - Windows Vista, 98, 95, ME
     - RHL 5.2, 6.0, 6.1, 6.2 (only nfs installs work)
2.  Add partition/disk size support to the TDL.
3.  Add improved error logging to guest installation.  That is, if the guest
installation fails, we want to get detailed error information out of the
installer to find out why.  Fedora/RHEL support doing remote syslog via
network or virtio-serial, and I also believe anaconda will dump data to syslog
during installation, so that is one avenue to pursue.  NOTE: anaconda
virtio-serial support does not exist until F-14.  See http://fedoraproject.org/wiki/Anaconda/Logging
4.  Instead of calling out to an external 'gvnccapture' command to collect
a screenshot, we should instead write the thing in python using the gtk-vnc
library.  Unfortunately I have not figured out how to do it in python yet,
so this needs further research.
5.  Before attempting an install, check the output_dir to make sure it will
approximately have enough space for the output disk image.
6.  Documentation on how to use the classes, and what new classes need to
provide.
7.  With windows from MSDN (at least 2000, maybe other versions too), the
top-level doesn't really contain the bits you care about.  What happens is
that there are 3 boot options on the CD: installer for Professional, Server, and
Advanced Server.  The directory structure on the CD is something like:

    english
        win2000
            adv_server
            pro
            server

and underneath each of (adv_server, pro, server) are the bits you care about.
To automate this you really need to figure out which one the user cares about,
then copy just that subdirectory.  You'll also need to extract the appropriate
parts of eltorito so it boots automatically, and then you'll also need to set
i386/txtsetup.sif [SetupData]: SetupSourcePath = "\".  See
http://old.bink.nu/bootcd/
8. Write a boxgrinder plugin.  This requires implementing a ruby class
for it, and implementing .after_init, .deliverables_exists?, .run, .deliverables.
9. Debian/Ubuntu packages.
10. Take a screen shot if some customization or generate-icicle steps time out.
11. Try to do automatic detection of distro/version/architecture from the ISO
that are provided to us.  That will make it so that a minimal TDL will only
include the path to the ISO, and we can figure out the rest of the information.
12. Add support for additional drivers during install (needed for Windows virtio
support).
13. Make "python setup.py bdist_rpm" work.  The problem is that bdist_rpm
generates its own SPEC file based on the information in setup.py.  When it
does this, it somehow messes up the %description (minor, probably a change to
the setup macro), fails to create the /var/lib/oz subdirectories (which could
be moved into setup.py as well), and also fails to find the gzipped man page
files (which is what eventually causes the build to fail).
14. RHL 6.2 does not work via HTTP because of a bug in the installer; when
parsing a URL passed in via "method", it fails to put a / at the beginning of
the URL.  What this means is that when the installer goes to fetch the install
images via "GET path/to/netstg2.img HTTP/0.9", the web server then returns an
error.  To do a fully automated install, we need to use an ISO, NFS or FTP
install method; I could not get FTP to work, but I did not try that hard.
15. RHL 6.1 fails because there is no netstg2.img available in the distribution
I have.  Unfortunately, I have not been able to find the netstg2.img, nor an
ISO of 6.1 to do an alternate install.  NFS may still work here.
16. RHL 6.0 fails because the kernel panics on boot:
     VFS: Cannot open root device 08:21
     Kernel panic: VFS: Unable to mount root fs on 08:21
17. Add some way to make multiple parallel builds of the same OS and type not
tromp on each other.  jclift has suggested that we have a lock file in place
that we check.

For example, if we are installing 2 F-14 x86_64 URL-based guests
at the same time, the first one in would create f14x86_64-url-<pid>.lock while
it is downloading the ISO file.  When the second install started, it would
look for the presence of that lock file; if the lockfile is not there, the
second install would go ahead and download the file.  If the lockfile is there
and the PID listed is still alive, the second install would assume the first
one is still downloading and wait in a poll loop.  If the lockfile is there and
the PID listed is not alive, then the second install would assume the first
install crashed, and proceed to re-download the file.

This works fine in all cases except for the "hung" install case.  That is, if
the first install hangs up somehow and is not downloading the necessary files,
this could cause other installs to hang indefinitely behind it.  This shouldn't
be a huge problem, though, because a) things don't hang up very often in this
manner, and b) the situation is really no worse than today, things would just
fail earlier.

18.  Enable SELinux in enforcing mode inside of Fedora/RHEL guests.  The current
problem with this is that prior to launching the customize step, we upload files
like ssh keys via libguestfs.  In the default mode libguestfs uploads them with
no SELinux context, which means reads are denied.

Jim Meyering suggests that we add a script to the end of /etc/rc.d/rc.local that
does a "restorecon" on the files we care about.  Then we don't need to worry
about knowing the context in Oz; we just make it do the right thing.  There
are two problems with this: 1) if we upload /etc/rc.d/rc.local, that will have
the wrong context that we have to deal with, and 2) there is a race condition
between icicle-nc checking in and this restorecon script finishing.  Neither
problem is insurmountable, but we should make the effort to get this working.

19.  Do preflight checks on detected bridges.  That is, if we detected the
bridge (i.e. it was not specified by the user), then we should do some basic
checks to make sure that we think it will work.  We should check the state
of at least:

    /proc/sys/vm/net/ipv4/ip_forward
    /proc/sys/net/bridge/bridge-nf-call-arptables
    /proc/sys/net/bridge/bridge-nf-call-ip6tables
    /proc/sys/net/bridge/bridge-nf-call-iptables
    iptables -t filter -L -v
    iptables -t nat -L -v

20.  We should add a mode where we assume the responsibility for uploading RPMs
into the guest (via ssh) and then doing a yum localinstall on those RPMs.
21.  We should add additional commands section.  In particular, we should have
"pre" package installation and "post" package installation command sections.
22.  On distributions that use NetworkManager, we can speed up the customization
and ICICLE generation step by using dbus-monitor to monitor when NetworkManager
has brought up the network.  This should save us an average of 30 seconds per
customization.
23.  Support hashes for the root password support.
24.  Add a mode where we use a reverse ssh tunnel with a SOCKS proxy to
download the packages.  This means that the packages need to be visible to the
imagefactory machine, but not necessarily to the instance.
25.  During customization/icicle generation, we should check to make sure that
the bridge listed in the libvirt XML matches up with what we detected (if
anything).  This isn't really an issue when doing oz-install -g -u, but if you
use the short-circuit oz-customize or oz-generate-icicle, the user could have
fed us bad data.
26.  In TDL.py, do a real schema validation using tdl.rng
